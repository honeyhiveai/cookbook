{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFFx7fPXALML",
        "outputId": "7d74d9ea-c9ff-4b3e-b05f-e062bf6663f9"
      },
      "outputs": [],
      "source": [
        "!pip install openai pymilvus honeyhive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7je0emfAQtx",
        "outputId": "2d8339f0-c9ad-46f4-e02b-088bcf61ad72"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from pymilvus import MilvusClient\n",
        "from honeyhive.tracer import HoneyHiveTracer\n",
        "from honeyhive.tracer.custom import trace\n",
        "\n",
        "# Initialize HoneyHive Tracer\n",
        "HoneyHiveTracer.init(\n",
        "    api_key=\"Your HoneyHive key\",\n",
        "    project=\"name of your project\",\n",
        ")\n",
        "\n",
        "# Initialize OpenAI client\n",
        "openai_client = OpenAI(api_key=\"your OpenAI key\")\n",
        "\n",
        "# Initialize Milvus client\n",
        "milvus_client = MilvusClient(\"milvus_demo.db\")  # Using Milvus Lite for demo\n",
        "\n",
        "def embed_text(text):\n",
        "    \"\"\"Generate embeddings using OpenAI's text-embedding-ada-002 model\"\"\"\n",
        "    res = openai_client.embeddings.create(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        input=text\n",
        "    )\n",
        "    return res.data[0].embedding\n",
        "\n",
        "@trace(\n",
        "    config={\n",
        "        \"collection_name\": \"demo_collection\",\n",
        "        \"dimension\": 1536,  # text-embedding-ada-002 dimension\n",
        "    }\n",
        ")\n",
        "def setup_collection():\n",
        "    \"\"\"Set up Milvus collection with tracing\"\"\"\n",
        "    # Drop collection if it exists\n",
        "    if milvus_client.has_collection(collection_name=\"demo_collection\"):\n",
        "        milvus_client.drop_collection(collection_name=\"demo_collection\")\n",
        "\n",
        "    # Create new collection\n",
        "    milvus_client.create_collection(\n",
        "        collection_name=\"demo_collection\",\n",
        "        dimension=1536  # text-embedding-ada-002 dimension\n",
        "    )\n",
        "\n",
        "@trace(\n",
        "    config={\n",
        "        \"embedding_model\": \"text-embedding-ada-002\"\n",
        "    }\n",
        ")\n",
        "def insert_documents(documents):\n",
        "    \"\"\"Insert documents with tracing\"\"\"\n",
        "    vectors = [embed_text(doc) for doc in documents]\n",
        "    data = [\n",
        "        {\n",
        "            \"id\": i,\n",
        "            \"vector\": vectors[i],\n",
        "            \"text\": documents[i],\n",
        "            \"subject\": \"general\"\n",
        "        }\n",
        "        for i in range(len(vectors))\n",
        "    ]\n",
        "\n",
        "    res = milvus_client.insert(\n",
        "        collection_name=\"demo_collection\",\n",
        "        data=data\n",
        "    )\n",
        "    return res\n",
        "\n",
        "@trace(\n",
        "    config={\n",
        "        \"embedding_model\": \"text-embedding-ada-002\",\n",
        "        \"top_k\": 3\n",
        "    }\n",
        ")\n",
        "def search_similar_documents(query, top_k=3):\n",
        "    \"\"\"Search for similar documents with tracing\"\"\"\n",
        "    query_vector = embed_text(query)\n",
        "\n",
        "    results = milvus_client.search(\n",
        "        collection_name=\"demo_collection\",\n",
        "        data=[query_vector],\n",
        "        limit=top_k,\n",
        "        output_fields=[\"text\", \"subject\"]\n",
        "    )\n",
        "\n",
        "    return [match[\"entity\"][\"text\"] for match in results[0]]\n",
        "\n",
        "@trace(\n",
        "    config={\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"prompt\": \"You are a helpful assistant\"\n",
        "    }\n",
        ")\n",
        "def generate_response(context, query):\n",
        "    \"\"\"Generate response using OpenAI with tracing\"\"\"\n",
        "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "@trace()\n",
        "def rag_pipeline(query):\n",
        "    \"\"\"Complete RAG pipeline with tracing\"\"\"\n",
        "    # Get relevant documents\n",
        "    relevant_docs = search_similar_documents(query)\n",
        "    # Generate response\n",
        "    response = generate_response(\"\\n\".join(relevant_docs), query)\n",
        "    return response\n",
        "\n",
        "def main():\n",
        "    # Sample documents\n",
        "    documents = [\n",
        "        \"Artificial intelligence was founded as an academic discipline in 1956.\",\n",
        "        \"Machine learning is a subset of artificial intelligence.\",\n",
        "        \"Deep learning is a type of machine learning based on artificial neural networks.\",\n",
        "        \"Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\",\n",
        "    ]\n",
        "\n",
        "    # Set up collection\n",
        "    setup_collection()\n",
        "\n",
        "    # Insert documents\n",
        "    print(\"Inserting documents...\")\n",
        "    insert_documents(documents)\n",
        "\n",
        "    # Test RAG pipeline\n",
        "    query = \"What is the relationship between AI and machine learning?\"\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    response = rag_pipeline(query)\n",
        "    print(f\"Response: {response}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
